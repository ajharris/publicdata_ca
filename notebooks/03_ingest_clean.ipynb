{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03: Data cleaning and merge\n",
    "\n",
    "This notebook combines StatCan and CMHC outputs into a single modeling table. It also checks how well metro names line up across sources so we can see where matches fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metro master crosswalk\n",
    "\n",
    "The master crosswalk gives each metro a stable `metro_id` and a clean name. This lets different datasets join reliably even when labels differ slightly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metros_master shape: (41, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_label</th>\n",
       "      <th>metro_name_source</th>\n",
       "      <th>province_source</th>\n",
       "      <th>metro_slug</th>\n",
       "      <th>is_partial</th>\n",
       "      <th>metro_id</th>\n",
       "      <th>matched</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ottawa-Gatineau, Ontario part, Ontario/Quebec</td>\n",
       "      <td>Ottawa-Gatineau</td>\n",
       "      <td>Ontario/Quebec</td>\n",
       "      <td>ottawa_gatineau</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>statcan_unemployment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ottawa-Gatineau, Quebec part, Ontario/Quebec</td>\n",
       "      <td>Ottawa-Gatineau</td>\n",
       "      <td>Ontario/Quebec</td>\n",
       "      <td>ottawa_gatineau</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>statcan_unemployment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       geo_label metro_name_source  \\\n",
       "0  Ottawa-Gatineau, Ontario part, Ontario/Quebec   Ottawa-Gatineau   \n",
       "1   Ottawa-Gatineau, Quebec part, Ontario/Quebec   Ottawa-Gatineau   \n",
       "\n",
       "  province_source       metro_slug  is_partial  metro_id  matched  \\\n",
       "0  Ontario/Quebec  ottawa_gatineau        True       NaN    False   \n",
       "1  Ontario/Quebec  ottawa_gatineau        True       NaN    False   \n",
       "\n",
       "                 source  \n",
       "0  statcan_unemployment  \n",
       "1  statcan_unemployment  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load processed metro tables + missingness diagnostics\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT = Path.cwd().resolve()\n",
    "if PROJECT.name == \"notebooks\":\n",
    "    PROJECT = PROJECT.parent\n",
    "PROCESSED = PROJECT / \"data\" / \"processed\"\n",
    "\n",
    "metros_master = pd.read_csv(PROCESSED / \"metros_master.csv\")\n",
    "missing_summary = pd.read_csv(PROCESSED / \"metro_join_missingness_summary.csv\")\n",
    "missing_unmatched = pd.read_csv(PROCESSED / \"metro_join_missingness_unmatched.csv\")\n",
    "\n",
    "print(f\"metros_master shape: {metros_master.shape}\")\n",
    "metros_master.head()\n",
    "\n",
    "missing_summary\n",
    "\n",
    "missing_unmatched"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling dataset (StatCan + CMHC)\n",
    "\n",
    "We keep only metros that appear in both sources (inner join). Missing values are not filled in yet; they are left as blanks so you can see where data coverage is thin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/andrewharris/Projects/housing-affordability/data/processed/metros_modeling.csv')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build modeling dataset from StatCan + CMHC outputs\n",
    "statcan = pd.read_csv(PROCESSED / \"statcan_metro.csv\")\n",
    "cmhc = pd.read_csv(PROCESSED / \"cmhc_metro.csv\")\n",
    "\n",
    "def normalize_metro_id(series):\n",
    "    return (\n",
    "        series.astype(str)\n",
    "        .str.strip()\n",
    "        .str.replace(r\"\\.0$\", \"\", regex=True)\n",
    "        .str.zfill(4)\n",
    "    )\n",
    "\n",
    "statcan[\"metro_id\"] = normalize_metro_id(statcan[\"metro_id\"])\n",
    "cmhc[\"metro_id\"] = normalize_metro_id(cmhc[\"metro_id\"])\n",
    "metros_master[\"metro_id\"] = normalize_metro_id(metros_master[\"metro_id\"])\n",
    "\n",
    "base = metros_master[[\"metro_id\", \"metro_name_std\", \"province\", \"metro_slug\", \"province_slug\"]]\n",
    "statcan_features = statcan.drop(columns=[\"metro_name_std\", \"province\"])\n",
    "cmhc_features = cmhc.drop(columns=[\"metro_name_std\", \"province\"])\n",
    "\n",
    "modeling = (\n",
    "    base.merge(statcan_features, on=\"metro_id\", how=\"left\")\n",
    "        .merge(cmhc_features, on=\"metro_id\", how=\"left\")\n",
    ")\n",
    "\n",
    "# Keep metros present in both sources; allow partial feature missingness.\n",
    "modeling = modeling[\n",
    "    modeling[\"statcan_reference_year\"].notna() & modeling[\"cmhc_rent_year\"].notna()\n",
    "].copy()\n",
    "\n",
    "modeling.sort_values(\"metro_name_std\", inplace=True)\n",
    "\n",
    "feature_cols = [\n",
    "    c for c in modeling.columns\n",
    "    if c not in {\"metro_id\", \"metro_name_std\", \"province\", \"metro_slug\", \"province_slug\"}\n",
    "]\n",
    "\n",
    "retained_summary = pd.DataFrame(\n",
    "    {\"metric\": [\"metros_total\", \"metros_retained\"],\n",
    "     \"value\": [len(metros_master), len(modeling)]}\n",
    ")\n",
    "\n",
    "missing_by_feature = pd.DataFrame(\n",
    "    {\"feature\": feature_cols,\n",
    "     \"missing_count\": modeling[feature_cols].isna().sum().values}\n",
    ")\n",
    "missing_by_feature[\"missing_pct\"] = (\n",
    "    missing_by_feature[\"missing_count\"] / len(modeling)\n",
    ").round(3)\n",
    "\n",
    "retained_summary\n",
    "missing_by_feature.sort_values(\"missing_count\", ascending=False)\n",
    "\n",
    "output_path = PROCESSED / \"metros_modeling.csv\"\n",
    "modeling.to_csv(output_path, index=False)\n",
    "output_path\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
